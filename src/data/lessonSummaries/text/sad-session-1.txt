Introduction: from Monoliths to Distributed SystemsServicios y Aplicaciones Distribuidas

Welcome and Objectives•Set expecta)ons and outcomes for the course.•Understand monoliths: strengths, weaknesses, and limits.•Recognize mo)va)ons for distributed architectures.•Preview the course structure and prac)cal focus.

What Is a Monolith?
•Single deployable applica)on containing UI, business logic, and data access.•All parts share the same run)me and are released together.•Op)mized for simplicity and speed in early product stages.

Monolith Deployment Model
•All-or-nothing deployments: even small changes ship the whole app.•Build, test, and release pipelines handle one artifact.•Acceptable with compact teams and limited feature sets; problematic at scale.

Why Monoliths Work Early
•Rapid iteration: one repo, one CI/CD pipeline, one artifact.•Simple onboarding and local development close to production.•End-to-end tests run in a single environment.

Modular Monoliths
•Well-deﬁned internal modules with clear interfaces.•Single compila)on and deployment unit for opera)onal simplicity.•Good stepping stone toward future extrac)ons.

Stress Signals in Monoliths
•Eroding module boundaries and increasing merge conﬂicts.•Longer builds and slower feedback loops.•Coordina)on boQlenecks: unrelated changes delay releases.

Regression Testing Burden
•Small features trigger broad regression testing.•Risk of breaking unrelated areas slows release cadence.•Bundled, infrequent releases increase failure blast radius.

Single Artifact Operational Risk
•Incidents force rollbacks that revert unrelated features.•Tight coupling across domains raises deployment risk.•Discourages continuous delivery practices.

When Monoliths Still Fit
•Small teams and constrained domains.•Low traﬃc or internal tools with modest SLAs.•Prototypes or short-lived products.

Transition Triggers•Sustained traﬃc growth and performance hotspots.•Need for independent release cadence per domain.•Rising incident frequency )ed to deployment coupling.•Long lead )mes and coordina)on overhead.

Distributed System: Definition
•Independent computers collaborate over a network.•Present a single coherent system to users.•Coordinate to share resources and tolerate partial failures.

Core Properties•Concurrency and parallelism for throughput.•Fault tolerance via replication and graceful degradation.•Scalability through vertical and horizontal strategies.•Transparency to hide distribution details from users.

Transparency in Practice
•Users should not care which node handled the request.•Loca)on, replica)on, and failure handling are invisible.•Achieved with load balancers, caches, smart clients.

Resource Sharing & Elasticity
•Pool compute, storage, and bandwidth across nodes.•Cloud plaWorms enable elas)c scaling up and down.•Op)mize cost/performance by matching capacity to load.

Concurrency vs Parallelism
•Concurrency: multiple tasks progress at once (interleaving).•Parallelism: tasks execute simultaneously on different cores/nodes.•Introduce coordination: locks, optimistic control, idempotency.

Fault-Tolerance Mindset
•Design for failure: assume components will fail.•Techniques: retries with backoff, circuit breakers, timeouts.•Graceful degradation and redundancy to keep service usable.

Scalability Basics
•Ver)cal scaling: add CPU/RAM to a single node.•Horizontal scaling: add more nodes/instances.•Horizontal favored for resilience and elas)city; requires statelessness.

The Network Tax
•Distributed calls incur latency and serializa)on overhead.•Poten)al for packet loss and retries.•Mi)gate with batching, eﬃcient protocols, and careful API design.

Consistency Realities
•Replicated state causes conflicts and stale reads.•Eventual consistency is common for availability and speed.•User experience patterns: versioning, conflict resolution, read-your-writes.

Security Surface Area
•More services and endpoints increase attack surface.•Strong authN/authZ, transport security, and secret management are mandatory.•Adopt zero-trust networking principles.

Operational Complexity
•Requires mature CI/CD, automated tes)ng, and IaC.•Health checks, metrics, logs, and tracing for observability.•On-call readiness and incident response playbooks.

Driver: Independent Releases
•Teams ship without wai)ng on unrelated components.•Service boundaries map to business domains.•Reduces coordina)on overhead and accelerates delivery.

Driver: Targeted Scaling
•Scale hotspots (e.g., checkout) independently of cold paths (e.g., admin).•Aligns cost with actual demand.•Avoids scaling the entire system unnecessarily.

Example Domain Split
•Orders, Payments, Products, Users, Notifications as separate domains.•Each owns its storage, APIs, and scaling policies.•Technology aligns with business boundaries.

Migration Path
•Start from modular monolith and iden)fy seams.•Extract the most independent or painful domains ﬁrst.•Establish plaWorm capabili)es: gateway, discovery, observability.

Trade-Offs to Acknowledge
•Agility and resilience vs added latency and coordina)on.•Opera)onal costs rise with more moving parts.•Architecture is economics: pay costs to unlock beneﬁts.

Key Takeaways (1)
•Monoliths are pragmatic and effective early on.•They become a liability with growth and coordination bottlenecks.•Recognize stress signals and plan ahead.

Key Takeaways (2)
•Distributed systems enable independence and scaling.•They introduce latency, consistency, security, and operational challenges.•Discipline and tooling are essential to succeed.

Common Misconceptions
•“Microservices are faster” — network overhead is real.•“Use many languages” — polyglot increases ops and hiring costs.•“More services is beQer” — follow domains and team boundaries.

Looking Ahead
•Next: deﬁne microservices precisely and contrast with distributed systems.•Discuss organiza)onal and technical implica)ons.•Iden)fy when NOT to adopt microservices.

Discussion
•Where has a monolith been a bottleneck in your experience?•Which domains would benefit most from independent deployments?

Closing
•You now have the vocabulary for why distributed systems exist.•Keep trade-offs in mind—they guide the rest of the course.