# Capítulo 6 · Procesamiento y reconocimiento del habla

## Objetivos
- Repasar la evolución histórica del reconocimiento de voz.
- Conocer arquitecturas actuales para sistemas ASR.
- Analizar retos prácticos y tendencias futuras.

## Historia breve
- **Años 50–90:** desde Audrey (Bell Labs) hasta sistemas HMM con modelos de lenguaje estadísticos.
- **2000s:** combinación GMM-HMM para mejorar modelado acústico.
- **2010s en adelante:** redes profundas (CNN, RNN, LSTM, GRU) y mecanismos de atención revolucionan el campo.

![Evolución de los sistemas de voz](figure:snlp-chapter-6/evolucion)
Caption: De modelos estadísticos discretos a arquitecturas end-to-end basadas en atención.

## Impacto del deep learning
- Automatiza extracción de características, captura dependencias de largo alcance y reduce tasas de error.
- Maneja mejor ruido, acentos, prosodia y habla conversacional.
- Habilita modelos end-to-end que mapean audio a texto sin etapas intermedias complejas.

## Aplicaciones actuales
- Asistentes virtuales, domótica y automoción.
- Soluciones empresariales: atención al cliente, transcripción de reuniones, biometría vocal.
- Salud: dictado clínico, monitorización remota, apoyo diagnóstico.

## Tendencias de la industria
- Procesamiento on-device para privacidad y latencia.
- Modelos multilingües y traducción simultánea.
- Personalización y adaptación continua al usuario.
- Integración multimodal con visión, AR/VR y sensores adicionales.

## Desafíos clave
- Variabilidad de la señal: ruido, micrófonos, acentos, velocidad.
- Ingeniería de modelos: gestionar longitud variable, requisitos de tiempo real, consumo de memoria.
- Entrenamiento: necesidad de grandes corpus balanceados, manejo de disfluencias.
- Adaptación: generalizar a nuevos dominios y hablantes, transfer learning eficaz.

## Arquitecturas ASR
- **RNN/LSTM/GRU:** procesan secuencias, pero limitadas por gradientes.
- **CNN:** capturan patrones locales en espectrogramas.
- **Modelos híbridos:** combinan CNN para feature extraction y RNN/attention para secuencias.
- **Transformers y conformers:** atención + convoluciones para contextos largos y precisión acústica.

## Sistemas end-to-end modernos
- CTC (Connectionist Temporal Classification) para alinear audio-texto sin etiquetas frame a frame.
- Modelos encoder-decoder con atención y variantes transducer.
- Integración con modelos de lenguaje externos para mejorar precisión.

## Consideraciones prácticas
- Pipeline de datos: limpieza, segmentación, normalización y augmentations (ruido, reverberación).
- Métricas: Word Error Rate (WER), Character Error Rate (CER), latencia, memoria.
- Despliegue: optimización en dispositivos móviles, cuantización, streaming.
- Futuro: modelos auto-supervisados, aprendizaje continuo y responsabilidad ética en uso de voz.
